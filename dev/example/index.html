<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Example · NormalizingFlows.jl</title><script data-outdated-warner src="../assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL=".."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../assets/documenter.js"></script><script src="../siteinfo.js"></script><script src="../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../assets/themeswap.js"></script></head><body><div id="documenter"><nav class="docs-sidebar"><div class="docs-package-name"><span class="docs-autofit"><a href="../">NormalizingFlows.jl</a></span></div><form class="docs-search" action="../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../">Home</a></li><li><a class="tocitem" href="../api/">API</a></li><li class="is-active"><a class="tocitem" href>Example</a><ul class="internal"><li><a class="tocitem" href="#Example:-Using-Planar-Flow"><span>Example: Using Planar Flow</span></a></li><li><a class="tocitem" href="#Evaluating-Trained-Flow"><span>Evaluating Trained Flow</span></a></li><li><a class="tocitem" href="#Reference"><span>Reference</span></a></li></ul></li><li><a class="tocitem" href="../customized_layer/">Customize your own flow layer</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Example</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Example</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/TuringLang/NormalizingFlows.jl/blob/main/docs/src/example.md#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h2 id="Example:-Using-Planar-Flow"><a class="docs-heading-anchor" href="#Example:-Using-Planar-Flow">Example: Using Planar Flow</a><a id="Example:-Using-Planar-Flow-1"></a><a class="docs-heading-anchor-permalink" href="#Example:-Using-Planar-Flow" title="Permalink"></a></h2><p>Here we provide a minimal demonstration of learning a synthetic 2d banana distribution using <em>planar flows</em> (Renzende <em>et al.</em> 2015) by maximizing the <a href="../api/#Evidence-Lower-Bound-(ELBO)">Evidence Lower Bound (ELBO)</a>. To complete this task, the two key inputs are:</p><ul><li>the log-density function of the target distribution, </li><li>the planar flow. </li></ul><h4 id="The-Target-Distribution"><a class="docs-heading-anchor" href="#The-Target-Distribution">The Target Distribution</a><a id="The-Target-Distribution-1"></a><a class="docs-heading-anchor-permalink" href="#The-Target-Distribution" title="Permalink"></a></h4><p>The <code>Banana</code> object is defined in <code>example/targets/banana.jl</code>, see the <a href="https://github.com/zuhengxu/NormalizingFlows.jl/blob/main/example/targets/banana.jl">source code</a> for details.</p><pre><code class="language-julia hljs">p = Banana(2, 1.0f-1, 100.0f0)
logp = Base.Fix1(logpdf, p)</code></pre><p>Visualize the contour of the log-density and the sample scatters of the target distribution:  <img src="../banana.png" alt="Banana"/></p><h4 id="The-Planar-Flow"><a class="docs-heading-anchor" href="#The-Planar-Flow">The Planar Flow</a><a id="The-Planar-Flow-1"></a><a class="docs-heading-anchor-permalink" href="#The-Planar-Flow" title="Permalink"></a></h4><p>The planar flow is defined by repeated applying a sequence of invertible transformations to a base distribution <span>$q_0$</span>.  The building blocks for a planar flow of length <span>$N$</span> are the following invertible transformations, called <em>planar layers</em>:</p><p class="math-container">\[\text{planar layers}: 
T_{n, \theta_n}(x)=x+u_n \cdot \tanh \left(w_n^T x+b_n\right), \quad n=1, \ldots, N, \]</p><p>where <span>$\theta_n = (u_n, w_n, b_n), n=1, \dots, N$</span> are the parameters to be learned.  Thankfully, <a href="https://github.com/TuringLang/Bijectors.jl"><code>Bijectors.jl</code></a> provides a nice framework to define a normalizing flow. Here we used the <code>PlanarLayer()</code> from <code>Bijectors.jl</code> to construct a  20-layer planar flow, of which the base distribution is a 2d standard Gaussian distribution.</p><pre><code class="language-julia hljs">using Bijectors, FunctionChains

function create_planar_flow(n_layers::Int, q₀)
    d = length(q₀)
    Ls = [f32(PlanarLayer(d)) for _ in 1:n_layers]
    ts = fchain(Ls)
    return transformed(q₀, ts)
end

# create a 20-layer planar flow
flow = create_planar_flow(20, MvNormal(zeros(Float32, 2), I))
flow_untrained = deepcopy(flow) # keep a copy of the untrained flow for comparison</code></pre><p><em>Notice that here the flow layers are chained together using <code>fchain</code> function from <a href="https://github.com/oschulz/FunctionChains.jl"><code>FunctionChains.jl</code></a>.  Alternatively, one can do</em></p><pre><code class="language-julia hljs">ts = reduce(∘, [f32(PlanarLayer(d)) for i in 1:20]) </code></pre><p><em>However, we recommend using <code>fchain</code> to reduce the compilation time when the number of layers is large. See <a href="https://github.com/TuringLang/NormalizingFlows.jl/blob/8f4371d48228adf368d851e221af076ff929f1cf/src/NormalizingFlows.jl#L52">this comment</a> for how the compilation time might be a concern.</em></p><h4 id="Flow-Training"><a class="docs-heading-anchor" href="#Flow-Training">Flow Training</a><a id="Flow-Training-1"></a><a class="docs-heading-anchor-permalink" href="#Flow-Training" title="Permalink"></a></h4><p>Then we can train the flow by maximizing the ELBO using the <a href="../api/#NormalizingFlows.train_flow"><code>train_flow</code></a> function as follows: </p><pre><code class="language-julia hljs">using NormalizingFlows
using ADTypes
using Optimisers

sample_per_iter = 10
# callback function to track the number of samples used per iteration
cb(iter, opt_stats, re, θ) = (sample_per_iter=sample_per_iter,)
# defined stopping criteria when the gradient norm is less than 1e-3
checkconv(iter, stat, re, θ, st) = stat.gradient_norm &lt; 1e-3
flow_trained, stats, _ = train_flow(
    elbo,
    flow,
    logp,
    sample_per_iter;
    max_iters=200_00,
    optimiser=Optimisers.ADAM(),
    callback=cb,
    hasconverged=checkconv,
    ADbackend=AutoZygote(), # using Zygote as the AD backend
)</code></pre><p>Examine the loss values during training:</p><pre><code class="language-julia hljs">using Plots

losses = map(x -&gt; x.loss, stats)
plot(losses; xlabel = &quot;#iteration&quot;, ylabel= &quot;negative ELBO&quot;, label=&quot;&quot;, linewidth=2) </code></pre><p><img src="../elbo.png" alt="elbo"/></p><h2 id="Evaluating-Trained-Flow"><a class="docs-heading-anchor" href="#Evaluating-Trained-Flow">Evaluating Trained Flow</a><a id="Evaluating-Trained-Flow-1"></a><a class="docs-heading-anchor-permalink" href="#Evaluating-Trained-Flow" title="Permalink"></a></h2><p>Finally, we can evaluate the trained flow by sampling from it and compare it with the target distribution. Since the flow is defined as a <code>Bijectors.TransformedDistribution</code>, one can easily sample from it using <code>rand</code> function, or examine the density using <code>logpdf</code> function. See <a href="https://turinglang.org/Bijectors.jl/dev/distributions/">documentation of <code>Bijectors.jl</code></a> for details.</p><pre><code class="language-julia hljs">using Random, Distributions

nsample = 1000
samples_trained = rand(flow_trained, n_samples) # 1000 iid samples from the trained flow 
samples_untrained = rand(flow_untrained, n_samples) # 1000 iid samples from the untrained flow
samples_true = rand(p, n_samples) # 1000 iid samples from the target

# plot 
scatter(samples_true[1, :], samples_true[2, :]; label=&quot;True Distribution&quot;, color=:blue, markersize=2, alpha=0.5)
scatter!(samples_untrained[1, :], samples_untrained[2, :]; label=&quot;Untrained Flow&quot;, color=:red, markersize=2, alpha=0.5)
scatter!(samples_trained[1, :], samples_trained[2, :]; label=&quot;Trained Flow&quot;, color=:green, markersize=2, alpha=0.5)
plot!(title = &quot;Comparison of Trained and Untrained Flow&quot;, xlabel = &quot;X&quot;, ylabel= &quot;Y&quot;, legend=:topleft) </code></pre><p><img src="../comparison.png" alt="compare"/></p><h2 id="Reference"><a class="docs-heading-anchor" href="#Reference">Reference</a><a id="Reference-1"></a><a class="docs-heading-anchor-permalink" href="#Reference" title="Permalink"></a></h2><ul><li>Rezende, D. and Mohamed, S., 2015. <em>Variational inference with normalizing flows</em>. International Conference on Machine Learning  </li></ul></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../api/">« API</a><a class="docs-footer-nextpage" href="../customized_layer/">Customize your own flow layer »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.25 on <span class="colophon-date" title="Wednesday 23 August 2023 19:42">Wednesday 23 August 2023</span>. Using Julia version 1.9.2.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
